### Denys Liubyvyi, UNI: dvl2110
### STAT W4240 
### Homework 2 , Problem 1
### Homework Due September 30


``` {r echo=FALSE}

#################
# Setup
#################
require(graphics)
require(fields)

#change working directory
setwd("/Users/dennis/github/W4240/HW2/")


cat("#######################################################################################
# a. (2 Points) Load hw02 q1 p1 fall14.csv. Find the column means and the row means for
# the data. What do these values tell us about this data set?
#######################################################################################")


#load file and clean the data
data1 <- read.csv("hw02_q1_p1_fall14.csv")
data1 <- na.omit(data1)

#see the data
#pairs(data1)


#calcuate means of rows
rows.means <- apply(data1,1,mean)
cat('Means of rows summary:')
#print(rows.means)
summary(rows.means)
#hist(rows.means,breaks = 50)

#calcuate means of columns
cols.means <- apply(data1,2,mean)
cat('Means of columns summary:')
#print(cols.means)
summary(cols.means)
#hist(cols.means,breaks = 50)


cat('It seems like the data is symmetric and unimodal')

cat("#######################################################################################
# b. (3 Points) Center the data and and find the empirical covariance matrix, 
# This should be a 5-by-5 matrix. What do the diagonal values of the covariance matrix 
# tell us about this data set? What do the off diagonal elements tell us about this 
# data set?
#######################################################################################")

#let's center the data!
data1.centered <- scale(data1,center=TRUE,scale=FALSE)
#pairs(data1.centered)
#cat("It seems like only scaled changed - but not the data")

#let's find the empirical covariance matrix
data1.cov <- cov(data1.centered)
cat('Our covariance matrix:')
print(data1.cov)


# check the dimensions
cat('Dimenstions of our covariance matrix:',nrow(data1.cov),'x',ncol(data1.cov))

# What do the diagonal values of the covariance matrix tell us about this data set?
cat('Covariance between X1 and X2 in the original data:',cov(data1[,1],data1[,2]))
cat('Diagonal X1<->X2 of the covariance matrix:',data1.cov[1,2],data1.cov[2,1])
cat('As we see, the entries on the diagonal of the covariance matrix are the 
variances of each element of the initial matrix.')

cat("#######################################################################################
# c. (5 Points) Give the eigenvalues and associated eigenvectors of Σˆ. 
# Why does this matrix have the same left eigenvectors as right eigenvectors?
#######################################################################################")

# get the right eigenvectors
data1.eigen.right <- eigen(data1.cov)
cat('The right eigenvectors:')
print(data1.eigen.right)

# get the left eigenvectors
data1.eigen.left <- eigen(t(data1.cov))  
cat('The left eigenvectors:')
print(data1.eigen.left)

cat("Since our initial covariance matrix is symmetric, transpose operation 
doesn't change it so our right eighten vectors and left eighten vectors are equal.")

cat("#######################################################################################
# d. (5 Points) Give all of the loadings and all of the scores for the data.
#######################################################################################")

#find the loadings
data1.loadings <- data1.eigen.right$vectors
cat('Data loadings:')
print(data1.loadings)

#find the scores
data1.scores <- data1.eigen.right$values
names(data1.scores) <- names(data1)
cat('Data scores:')
print(data1.scores)

cat("#######################################################################################
# e. (5 Points) Plot the proportion of variance captured against the number of 
# components included. How many components should we include and why?
#######################################################################################")
barplot(data1.scores)

cat('Defenitely we should include to our analysis two first components because they covers most of the variance in the data')
pc <- data1.loadings[,1:2]

cat("#######################################################################################
# f. (5 Points) Load hw02 q1 p2 fall14.csv. This has 5 new observations in the 
# original coordinates. Give their scores.
#######################################################################################")

#load file with new observations and clean the data
data1.2 <- as.matrix(read.csv("hw02_q1_p2_fall14.csv"))
data1.2 <- na.omit(data1.2)
data1.2.center <- scale(data1.2,scale=FALSE,center = TRUE)

cat('Dimenstions of our data:')
print(dim(data1.2))

#give their scores
cat('Scores of our data:')
ppc <- prcomp(data1.2)
#names(ppc)
#plot(ppc)
screeplot(ppc,type="lines")

cat("#######################################################################################
# g. (5 Points) Now use only the first two scores to represent the observations 
# from the previous part. What are the coordinates of the projections in the original 
# space, x′? What is their Euclidean distance from the original data points?
#######################################################################################")


#aplly 2 pc to the data and back
data1.2.back <- data1.2.center %*% pc %*% t(pc)

cat("What are the coordinates of the projections in the original space, x':")
print(data1.2.back)

#calculate distances
dist <- rdist(data1.2.back,data1.2.center)
cat('Euclidian distance from the original data points:',diag(dist))

cat("#######################################################################################
# h. (5 Points) Define the error of a point as
# d(x′, x) = x′ − x,
# which is a 5-dimensional vector of errors. In what direction is d(x′,x) 
# for the 5 new points? Why do you think this is?
#######################################################################################")

#calculate errors
errors <- data1.2.back-data1.2.center
cat('Error of a point:')
print(errors)
cat("We loose part of information when we project the data to two-dimensional 
space and then project it back. We generally keep the % of information 
only associated with two first principal components. That's why we have this error.")

```